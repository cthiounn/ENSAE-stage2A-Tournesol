\section{Tournesol et Mehestan : construction d'un algorithme robuste sur des données collaboratives dans un monde éthique}

\subsection{Présentation générale}

La plateforme collaborative Tournesol, accessible en ligne avec un navigateur à l'adresse
\href{https://tournesol.app}{tournesol.app}, est un espace coopératif où chacun peut contribuer en effectuant des comparaisons entre deux entités (vidéos, candidats). Après inscription et une fois authentifié, la plateforme offre la possibilité de comparer deux entités, de gérer une liste d'entités à comparer et de visualiser ses propres comparaisons effectuées. Tout internaute peut visualiser les recommandations générales ou par critère de la plateforme, après calcul et classement par l'algorithme Mehestan.

Aujourd'hui, la plateforme Tournesol est principalement centrée sur la comparaison et la recommandation de vidéos hébergées sur Youtube. La plateforme est conçue à être générique dans la recommandation d'entités et est donc capable de proposer des comparaisons sur d'autres champs, tel que le choix d'un candidat comme pour l'élection présidentielle 2022, ou pour des revues par les pairs d'articles scientifiques.


À l'aide des contributions, l'algorithme Mehestan a pour objectif d'harmoniser toutes les notations deux à deux et de calculer un score global pour chaque entité de manière robuste. En effet, un contributeur ne devrait pas être un contributeur pivot\footnote{~En microéconomie, un agent est dit pivot si sa présence ou son absence caractèrise le résultat de production d'un bien public.} d'un score d'une entité afin d'éviter des stratégies sous-optimales et des attaques mal intentionnées de manipulation de l'information.

\begin{figure}[ht]
  \includegraphics[width=\linewidth]{tournesol.png}
  \caption{Interface de la plateforme Tournesol}
  % \vspace{-15pt}
\end{figure}


\subsection{Objectif de Tournesol : "A better attention is all we need"}



Les scores calculés permettent dans un premier temps de proposer une page de recommandation générale. L'utilisateur a la possibilité de filtrer par critères ou de donner des poids différents aux critères afin de construire sa propre page de recommandation. Dans un monde où la volumétrie de l'information est difficilement appréhendable pour le cerveau humain, les systèmes de recommandations actuels ne sont pas satisfaisants au regard de l'intérêt commun, car ces systèmes sont conçus pour répondre à l'intérêt privé des entreprises, \textit{i.e.} maximiser la captivité de l'attention des utilisateurs. 

L'objectif premier de Tournesol est donc de proposer des informations recommandées pour le bien commun, que la plateforme met en avant. Loin de vouloir corriger tous les biais, la plateforme Tournesol introduit un biais particulier, le biais du jugement des contributeurs, afin de réinternaliser le coût social et de mieux répondre aux préférences des utilisateurs en termes d'accès à l'information. En ce sens, l'objectif de Tournesol n'est donc pas de proposer des recommandations de manière "neutre", mais avec une visée éthique.

Les informations recommandées prennent tout d'abord la forme de recommandation globale. Le coeur de l'algorithme Mehestan est en premier lieu de proposer une quantification de la désirabilité globale des entités, par l'aggrégation robuste des préférences individuelles. L'algorithme permet alors d'avoir une relation d'ordre et de proposer cette hiérarchisation à l'ensemble des internautes \footnote{~\href{https://tournesol.app/recommendations?date=Month&language=}{https://tournesol.app/recommendations?date=Month&language=}}.

De plus, l'internaute peut personnaliser ses recommandations en choississant des filtres et en sélectionnant des critères. Tournesol propose de constituer un indicateur composite personnalisé afin d'affiner ses recommandations et ainsi de proposer des entités proches de ses préférences individuelles. Ce système de recommandations favorise alors une découvrabilité personnalisée d'entités recommandables.

Compte tenu de l'importance de la qualité de l'information, l'algorithme de Tournesol doit être robuste et sécurisé. En particulier, l'algorithme doit être robuste à la contamination de données, aux attaques coordonnées de manipulation de l'information ou attaques bizantines. De même, la plateforme doit être sécurisé et garantir l'intégrité du processus et des données soumises par les contributeurs, ainsi que respecter l'éventuel anonymat choisi des préférences individuelles.


Au delà de proposer des recommandations, Tournesol a pour ambition de constituer une base de données éthique et collaborative de grande envergure, afin de devenir un standard de facto et de montrer qu'il est possible d'allier éthique et IA et de guider les entités privés à emboîter le pas. Pour cela, un des objectifs finaux de Tournesol est de promouvoir des données collaboratives éthiques en open data et spécifiquement à destination des chercheurs en science des données.

\subsection{Modélisation statistique}

Dans le cadre d'une modélisation statistique bayésienne, sous hypothèse qu'il existe pour chaque entité un score réel avec une relation d'ordre, soit $\theta_{a}\in\Theta=\mathbf{R}$ le paramètre à estimer représentant le score de l'entité a.

Le contributeur n compare deux entités a et b en notant selon un critère principal et un ou plusieurs critères secondaires optionnelles sur une échelle de $R_{min}=-10$ à $R_{max}=10$.

Une comparaison est donc un 4-uplet (n, a, b, liste de couple notation-critère (r,c))

Le score utilisé pour la recommandation est actuellement calculé sur le critère principal et les scores sur les autres critères secondaires sont calculées de manière approximativement similaire. Ainsi, la suite de ce rapport se focalisera sur le calcul du score du critère principal à partir des notations sur ce critère principal.

\begin{figure}[ht]
  \includegraphics[width=\linewidth]{comparison.png}
  \caption{Exemple d'une comparaison entre deux vidéos}
  % \vspace{-15pt}
\end{figure}
\subsubsection{Approche bayésienne pour un problème inverse}

La plateforme Tournesol collecte les préférences déclarées des contributeurs et cherche à en déduire les préférences réelles à partir de ces observations. L'inférence des valeurs réelles à partir des observations constitue le coeur des problèmes inverses, à partir d'une transformation linéaire ou non entre observations et valeurs réelles. Pour cela, l'approche bayésienne permet d'estimer ces valeurs réelles en effectuant quelques hypothèses.

\begin{hypothesis}\label{hyp1}
Les recommandations formulées par un contributeur sont à un bruit près les véritables préférences du contributeur.
\end{hypothesis}
\begin{hypothesis}\label{hyp2}
Pour des raisons de parcimonie de calcul, le bruit est considéré gaussien et indépendant temporellement entre chaque comparaison d'un même contributeur. Cette hypothèse simplificatrice peut être remise en compte et améliorée. Dans une première version, Tournesol adopte cette hypothèse simplificatrice afin de pouvoir proposer un premier système de recommandation robuste.
\end{hypothesis}

\begin{hypothesis}\label{hyp3}

Les recommandations d'un contributeur sont supposées indépendantes. Soit $R_{ab}$ la variable aléatoire discrète dans $[\![-10,10]\!]$ représentant la note entre A et B, $(R_{ab})_{ab \in AB} \sim P_{\theta^\dagger_{ab}}$ avec AB l'ensemble des recommandations du contributeur, par le lemme des coalitions toute transformation de  $(R_{ab})_{ab \in AB}$ garde l'indépendance.

\end{hypothesis}


\subsubsection{Modélisation du problème inverse}
Soient r (ou $r_{ab}$), la notation du contributeur n entre les entités a et b

et $\Tilde{r}$, la notation normalisé entre (-1,1) avec $\Tilde{r} =r/(1+R_{max})$ et $R_{max}=10$

et la fonction continue et dérivable $\ell : (-1,1) \rightarrow \mathbf{R}$ définie par $\ell : \Tilde{r} \rightarrow -\Tilde{r}/\sqrt{1-\Tilde{r}^2}$,

alors, la fonction inverse est $\Tilde{r} : \mathbf{R} \rightarrow  (-1,1) ; \Tilde{r} : \ell \rightarrow -\ell / \sqrt{1+\ell²} $ avec $r(\ell)= \Tilde{r}(\ell)(1+R_{max})$

Soit $\theta_{ab}^\dagger=\theta_a^\dagger-\theta_b^\dagger$, avec $\theta_a^\dagger, \theta_b^\dagger$ les vrais scores des entités a et b par le contributeur n, les hypothèses  \ref{hyp1} et \ref{hyp2} se traduisent par

\begin{equation}
r_{ab}=r(\theta_{ab}^\dagger)+\zeta_{ab}    
\end{equation}


avec $\zeta_{ab}$ un bruit gaussien centré d'écart type $(1+R_{max})\sigma_0$\footnote{~Le choix est fait ici pour simplifier les calculs à défaut d'\textit{a priori}, il peut être affiné par la suite}.
En appliquant $\ell$ à $\Tilde{r}(\theta_{ab}^\dagger)$, $\theta_{ab}^\dagger = \ell (\frac{( r_{ab}-\zeta_{ab})}{(1+R_{max})})$.
Cette quantité s'approche avec un développement limité au premier ordre par $\ell(\Tilde{r_{ab}}) - \ell'(\Tilde{r_{ab}})\frac{\zeta_{ab}}{(1+R_{max})}$ avec $\ell'(\Tilde{r})=(1-\Tilde{r}^2)^{-3/2}$

\begin{equation}
    \theta_{ab}^\dagger \approx \ell(\Tilde{r_{ab}}) - \ell'(\Tilde{r_{ab}})\frac{\zeta_{ab}}{(1+R_{max})}
\end{equation}

$\zeta_{ab}$ est une variable aléatoire gaussienne centrée d'écart type $(1+R_{max})\sigma_0$  par hypothèse
et $\theta_{ab}^\dagger$ et $r_{ab}$ sont des observations de variables aléatoires respectivement $\theta$ et R suivant des lois \textit{a priori} dans $\mathbf{R}$ et R à support discret.

\subsubsection{Résolution du problème inverse}

Les recommandations d'un contributeur donne des informations sur l'ensemble des $\set{\theta^\dagger_a : a \in A}$, avec A l'ensemble des entités notés.
En particulier, une recommandation entre a et b est à la fois une contribution pour $\theta^\dagger_a$ et à la fois pour $\theta^\dagger_b$.

Dans cette partie, R est le vecteur aléatoire des observations empilés.
Soit $\theta$, le vecteur aléatoire des $\theta^\dagger$ empilés
et soit $\pi(\theta)$ le prior de $\theta$ comme le produit de loi normale d'écart-type $\frac{\sigma_0}{\alpha_{prior}}$, avec $\alpha_{prior}$ un coefficient positif de pénalisation du \textit{prior}. Plus $\alpha_{prior}$ est petit, moins le prior n'a d'influence dans la modélisation.

La formule de Bayes donne  
\begin{equation}
\pi(\theta|R) = \frac{f(R|\theta)\pi(\theta)}
{\int_{\Theta} f(R|\theta)\pi(\theta) \,d\theta }
\end{equation}

ou  

\begin{equation}
\pi(\theta|R) \propto f(R|\theta)\pi(\theta)
\end{equation}

avec

\begin{equation}
 f(R=r|\theta=\theta^\dagger)= \prod_{ab \in AB} \frac{1}{\sigma_0\ell'(\Tilde{r_{ab}})\sqrt{\tau}}\exp \left( -(\frac{\ell(\Tilde{r_{ab}})-\theta_{ab}^\dagger}{\sqrt{2}\sigma_0\ell'(\Tilde{r_{ab}})})^2 \right)    
\end{equation}
  avec  $\tau=2\pi$

\begin{equation}
 \pi(\theta)= \prod_{a \in A} \frac{1}{\sigma_0\sqrt{\tau}}\exp \left( -(\frac{\alpha_{prior}\theta^\dagger_a}{\sqrt{2}\sigma_0})^2 \right)    
\end{equation}


%$  -\ln{P(\ell|\theta^\dagger)}= \sum_{(a,b)\in AB} \frac{k_{ab}}{2\sigma_0^2}  (\ell(\Tilde{r_{ab}})-\theta_{ab}^\dagger)^2 + K $ avec K une constante réelle et AB l'ensemble des comparaisons entre deux paires d'entités%
La log-vraisemblance négative \textit{a posteriori} s'écrit avec une constante K ne dépendant pas de $\theta$ :

\begin{equation}
 -log \mathcal{L} \triangleq -\log{\pi(\theta|R)} = -log(f(R|\theta))  -log(\pi(\theta))+ K     
\end{equation}


\begin{equation}
 -log \mathcal{L} = - log(f(R|\theta)) - log(\pi(\theta))+ K     
\end{equation}

\begin{equation}
 -log \mathcal{L} = \frac{1}{2\sigma_0^2} \left( \sum_{ab \in AB} k_{ab}(\ell(\Tilde{r_{ab}})-\theta_{ab}^\dagger)^2 + \alpha_{prior}\sum_{a \in A}{\theta^\dagger_a}^2 \right) + K'     
\end{equation}

avec $k_{ab} = \frac{1}{\ell'(\Tilde{r_{ab}})^2}$,

L'estimateur du maximum \textit{a posteriori} se déduit des conditions du premier ordre de la log-vraisemblance négative \textit{a posteriori} car le problème est fortement convexe.

\begin{equation}\label{equation:cpo}
\forall a \in A, \sigma_0^2\frac{\partial{log\mathcal{L}}}{\partial{\theta_a^\dagger}} = 0 = \alpha_{prior}\theta^\dagger_a - \sum_{ab \in AB}k_{ab}(\ell(\Tilde{r_{ab}})-\theta_{a}^\dagger-\theta_{b}^\dagger)
\end{equation}

L'équation (\ref{equation:cpo}) établit un système d'équations linéaires à résoudre. Il peut s'écrire sous la forme matricielle $\theta^*=K^{-1}L$ avec K une matrice inversible et $\theta^*$ l'estimateur du maximum \textit{a posteriori} (MAP), avec $K = Mat(diag(\alpha_{prior}+\sum_{b \in N(A)} k_{ab}))   - Mat(k_{ab}) $
et $L = Vect(\sum_{b \in N(A)} k_{ab}\ell(\Tilde{r_{ab}}))$.
K est une matrice à diagonale dominante et strictement dominante pour tout $\alpha_{prior}$ strictement positif. En vertu du lemme d'Hadamard, K est inversible et assure l'unicité et l'existence de l'estimateur MAP, estimant le mode de la vraisemblance \textit{a posteriori}.

La variance de cet estimateur se calcule à partir du score du posterior et est l'inverse de l'information de Fisher\footnote{~Sous hypothèse de régularité du modèle.}. Il se déduit de l'estimation de $\sigma^2_0$ en supposant un prior égal à 1.

\begin{equation}
Var(\score)= (\frac{\partial²{-log \mathcal{L}_{ab}}}{\partial{\theta^\dagger_a}^2})^{-1}=\frac{1}{\sigma_0^2}\left( \alpha_{prior} + \sum_{ab \in AB} k_{ab} \right)
\end{equation}

\begin{equation}
\hat{\sigma_0}^2 =\frac{1}{card(AB)} \left( 1 + \sum_{ab \in AB} k_{ab,t}(l_{ab,t} - \score_{ab})^2 \right)
\end{equation}

Dans la suite de ce rapport, l'incertitude relative à un score réfère à l'écart-type plug-in de l'estimateur MAP.

\subsection{Fonctionnement de l'algorithme Mehestan}

Cette sous-section présente de manière succinct l'algorithme Mehestan. La construction des scores individuels est le pivot de l'algorithme et l'heuristique souhaité vise à réduire sa complexité algorithmique. Mesurer la qualité de l'heuristique revient à mesurer les écarts entre l'algorithme Mehestan et les résultats de l'heuristique sur cette partie, car cette dernière se substitue à la première. Néanmoins, pour avoir une idée plus précise de l'impact sur les scores finaux de Tournesol, il est nécessaire d'en comprendre leur construction et notamment la volonté d'obtenir des scores robustes aux attaques d'utilisateur malveillant voulant manipuler ces scores.
L'algorithme Mehestan fonctionne en trois phases :

\begin{enumerate}
    \item Construction des scores individuels
    \item Construction du réétalonnage et des scores normalisés
    \item Construction des scores des entités
\end{enumerate}
\subsubsection{Construction des scores individuels}

Pour chaque contributeur, à partir de sa matrice de comparaison $r_t$, la première partie de l'algorithme calcule le vecteur des scores individuels bruts et des incertitudes à partir des formules énoncées précédemment.

\begin{algorithm}
\renewcommand{\algorithmcfname}{Algorithme}
\caption{Calcul des scores individuels et des incertitudes par inversion matricielle}\label{alg:local_scores_matrix_inversion}
\KwData{la matrice de comparaison $r_t$, l'hyperparamètre de l'a priori $\alpha_{prior}$}
\KwRes{les scores individuels $\score$ et l'incertitude associée $\deltascore$}

$\Tilde{r_t} \leftarrow r_t/(1+R_{max})$

$\ell_t \leftarrow -\Tilde{r_t}/\sqrt{1-\Tilde{r_t}^2}$

$k_t \leftarrow (1-\Tilde{r_t}^2)^3$

$K_{aa,t} \leftarrow \alpha_{prior} + \sum_{b \in N(A)} k_{ab,t}$

$L_t \leftarrow \sum_{b \in N(A)} k_{ab,t}l_{ab,t}$

$K_t \leftarrow Mat(diag(K_{aa,t})) - k_t $ 

$\score \leftarrow K_t^-1 L_t$

$\deltascore \leftarrow \frac{1}{card(AB)} \left( 1 + \sum_{ab \in AB} k_{ab,t}(l_{ab,t} - \score_{ab})^2 \right)$

\Return{$\score, \deltascore$}
\end{algorithm}

\begin{exemple}\label{example:n1}



Soit un contributeur \textit{i} ayant fait une comparaison entre $E_{1}$ et $E_{2}$ avec une notation $n_{1-2} \in [\![-10;10]\!]$

$r_{t}= \begin{pmatrix}
0 & n_{1-2} \\
-n_{1-2} & 0 
\end{pmatrix}$

$l_{t}= \begin{pmatrix}
0 & l_1 \\
-l_1 & 0 \\
\end{pmatrix}
$

$k_{t}= \begin{pmatrix}
0 & k_1 \\
k_1 & 0 \\
\end{pmatrix}
$

$K_{aa,t}= \begin{pmatrix}
\alpha + k_1\\
\alpha +  k_1\\
\end{pmatrix} 
$

$L_{t}= \begin{pmatrix}
l_1 k_1\\
-l_1 k_1 \\
\end{pmatrix} 
$

$K_{t}= \begin{pmatrix}
\alpha + k_1 & -k_1 \\
-k_1 & \alpha + k_1 \\
\end{pmatrix}
$

$\score= \frac{1}{(\alpha + k_1)^2-k_1^2} \begin{pmatrix}
\alpha + k_1 & k_1 \\
k_1 & \alpha + k_1 \\
\end{pmatrix}\begin{pmatrix}
l_1 k_1\\
-l_1 k_1 \\
\end{pmatrix} 
= 
\begin{pmatrix}
l_1k_1 / (\alpha + 2k_1)\\
-l_1k_1 / (\alpha + 2k_1)\\
\end{pmatrix} 
$
\end{exemple}
\subsubsection{Construction du réétalonnage et des scores normalisés}

Avant d'agréger les scores individuels, il est nécessaire de réétalonner ces scores sur une même échelle. L'algorithme calcule un noyau d'utilisateur de référence puis calcule tous les réétalonnages de chaque utilisateur par rapport à ce noyau. Pour cette étape, l'algorithme utilise \gls{qrmed} pour calculer le facteur d'homothétie $\textit{s}_{nm}$ médian et le facteur de translation $\tau_{nm}$ médian à appliquer entre deux contributeurs \textit{n} et \textit{m}, puis utilise la \gls{brmean} pour en extraire des facteurs \textit{s} et $\tau$ moyens\footnote{~Cette partie de l'algorithme ici présentée a été fortement vulgarisée pour être facilement accessible. En réalité, l'algorithme est bien plus complexe que cela.}.

\begin{equation}
    \gls{qrmed}_W(w,x) = \operatorname*{argmin}_{z \in \mathbf{R}} \set{ Wz^2 + \sum_{i=1}^n w_i|x_i-z|}
\end{equation}

avec W le paramètre de résilience Byzantine.

\begin{equation}
    \gls{brmean}_W(w,x) = \frac{1}{\lVert w \rVert_1} \sum_{i=1}^n w_iCLIP(x_i,\gls{qrmed}_{4W}(w,x),
    \frac{\lVert w \rVert_1}{4W})
\end{equation}
avec CLIP(x, centre, longueur) la fonction qui tronque x dans l'intervalle $[centre \pm longueur]$

\begin{equation}
    \textit{s}_{nm}= \gls{qrmed}_1(1,\set{ \frac{|\score_{an}-\score_{bn}|}{|\score_{am}-\score_{bm}|} : ab \in AB})
\end{equation}
\begin{equation}
    \tau_{nm}= \gls{qrmed}_1(1,\set{ s_n\score_{an} - s_m\score_{am} : a \in A })
\end{equation}

\begin{equation}
\textit{s}=1+\gls{brmean}_{8W\lVert \score \rVert_\infty}(\set{w_m : m \in Voisin(n)},\set{s_{nm}-1 : m \in Voisin(n)})
\end{equation}
avec $w_m$ le droit de vote de l'utilisateur \textit{m}
\begin{equation}
\tau=  \gls{brmean}_{8W}(\set{w_m : m \in Voisin(n)},\set{\tau_{nm} : m \in Voisin(n)})
\end{equation}

Grace à ces deux facteurs, les scores normalisés $\theta^\circledS$ sont calculés par transformation affine :
\begin{equation}
\theta^\circledS=\textit{s}\score + \tau
\end{equation}


\subsubsection{Construction des scores des entités}

L'algorithme calcule les scores globaux $\theta^g$ en utilisant \gls{qrmed} sur les scores normalisés des contributeurs pour chaque entité et ramène tous les scores entre [-100,100] par une bijection avec l'arc-tangente.

\begin{equation}
    \forall a \in A , \theta^g_a=\gls{qrmed}_{2W}(w,\theta^\circledS_a)
\end{equation}


\pagebreak

